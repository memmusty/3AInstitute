<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Maker Project: Traffic Controller</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.13.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="#page-top">Memunat I.</a><button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">Menu<i class="fas fa-bars"></i></button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="build.html#skills">Skills</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#activities">Activities</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <!-- Projects-->
        <section class="projects-section bg-light" id="projects">
            <div class="container">
                <div class="row align-items-center mb-4 mb-lg-5">
                    <div class="project-text">
                        <h1>Maker Project - An Intelligent Traffic Controller with Computer Vision</h1>
                        <hr class="d-none d-lg-block mb-4 ml-0" />
                        <div class="col-lg-12">
                            <img class="img-fluid" src="assets/img/demo-image-header.jpg" alt="" />
                        </div>
                        <br/>
                        
                        <h3>Introduction</h3>
                        <p>
                            This page provides a presentation of an intelligent crossroad traffic control system  I developed as my maker project in the first semester of CECS8001, and my challenges as I progressed in building it. The maker project was aimed at building a system that is  related to the new branch of engineering, solves a problem we are motivated about, learn new skills while at it. I decided to build computer-vision based traffic controller because of my experience with the limitations of timer-based traffic controllers in Lagos, Nigeria. Also, I was excited to experiment with and build on my machine learning and computer electronics skills. Applying the skills I learned over the semester, I developed an autonomous real-time computer-vision based traffic controller that controls traffic based on the sensed current state of the traffic. 
                        </p>

                        <h3>Motivation: Traffic Congestion in Lagos</h3>
                        <p>
                            Lagos is one of the most congested cities in the world with approximately 13 million inhabitants in 2015 - most of which are cars owners and youths. Even in the presence of traffic warden and timer-based traffic lights on every road, there is rarely a time where Lagos main roads are not congested with residents in cars, buses, tricycles, bikes, etc. As a working resident, there are days I had spent approximately 2 hours on a spot (seated in a bus) in the traffic. On an average, I spend a total of 5 hours on the road to and from my workplace daily - that is, if am able to avoid a really congested traffic. Lagos is tagged the third most stressful city in the world - some will say Lagos traffic is a tourist attraction on its own.
                        </p>
                        <p>
                            This increasing traffic congestion has posed lots of troubles and challenges for Lagosians which includes:
                            <ul>
                                <li>Increased accidents while trying to avoid rush-hour.</li>
                                <li>Exposing the lives of Lagos workers to danger as they have to leave their homes as early as 3 a.m-4 a.m and return home late in the night.</li>
                                <li>Stress, poor immune system and health problems.</li>
                                <li>In cases of emergencies, a serious gridlock can result in loss of lives.</li>
                                <li>Missed opportunities like job interviews, business meetings, flight schedule etc.</li>
                            </ul>
                            In addition to these, the timer-based traffic controller is usually is insensitive to unpredicted traffic scenarios and controls the traffic blindly. These motivated me build an intelligent traffic controller that can effectively replace the timer-based ones. The developed traffic light functions as seen below.
                            <iframe src="https://player.vimeo.com/video/430589280" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
                        </p>
                        <h3>Key Skills and Components</h3>
                        <ul>
                            <li>Raspberry pi</li>
                            <li>Male to Female jumper wires</li>
                            <li>Light Emitting Diodes (LEDs)</li>
                            <li>Raspberry pi camera</li>
                            <li>Coral Edge TPU USB Accelerator</li>
                            <li>Monitor</li>
                            <li>External Keyboard</li>
                            <li>External Mouse</li>
                            <li>Resistors</li>
                            <li>Breadboard</li>
                            <li>Ethernet Cable</li>
                            <li>SD card</li>
                            <li>USB Cable</li>
                            <li>MobileNet SSD v2 (COCO) â€“ a TFLite object detection model</li>
                            <li>Traffic controller program (in Python)</li>
                            <li>Code Editor: Mu Code</li>
                        </ul>
                        <figure class="col-lg-8" >
                            <img class="img img-fluid" src="assets/img/demo-components.jpg" alt="" />
                            <figcaption><em>A snapshot of some of the components</em></figcaption>
                        </figure>
                        <h3 id="activities">Activities</h3>
                        <h4>Project Planning and Initiation</h4>
                        <p>
                            This involved reflecting on the type of solution I wanted to build and the tools I need to bring it to scale. I began with deciding what traffic I wanted to build the traffic controller for. I decided to a traffic controller for a 4-way crossroad because most of Lagos busy roads are usually of this form and it is a complex traffic - starting with it helps me understand other roads. After this, I discussed with Johan, and we came up with a sketch of the traffic and a formal definition of the problem as seen below. This was a starting point for me in designing the logic of the traffic controller.                           
                            <div class="col-lg-8">
                                <img class="img-fluid" src="assets/img/demo-traffic-plan.jpg" alt="" />
                                <figcaption>A model of a 4-way crossroad traffic</figcaption>
                            </div>
                            In determining the technologies I would use in building it, I had to reflect on the challenges that could come up when this scales - the cost of deploying Lagos roads (magnetic roads Vs. computer vision), the possibilities of internet disconnections or electricity outages in places where this is deployed. The thoughts of this made me want a solution that is fully functional offline and have a backup source of power in case of power outage. This made me decide to build a prototype using raspberry pi, LEDs, and pi camera. The following describes the system development process in details.
                        </p>
                        <h4>Setting Up Raspberry Pi and Pi Camera</h4>
                        <p>
                            This activity was guided by the detailed instructions for setting up the Raspberry Pi on the <a href="https://projects.raspberrypi.org/en/projects/raspberry-pi-getting-started">getting started</a>. The activity went as follows:
                            <ul>
                                <li>Downloaded the Raspberry Pi <a href="https://www.raspberrypi.org/downloads/">Imager</a> for Windows and used the imager to Install Raspbian on my SD card</li>
                                <li>Inserted the SD card Raspberry pi to install the Raspbian Operating System (OS), connected the monitor, keyboard, mouse, pi camera, and ethernet cable to their respective ports, then connected electrical power to pi via USB cable.</li>
                                <figure class="col-lg-6" >
                                    <img class="img img-fluid" src="assets/img/demo-raspbian-install.jpg" alt="" />
                                    <figcaption><em>A snapshot of some of the components</em></figcaption>
                                </figure>
                                <li>Once pi booted, I finished setting up following the prompts, and set my password. This was followed by an auto-update of Raspbian OS (the ethernet cable connected it to Wi-Fi); I had to restart it for the update to be completed.</li>
                                <li>Connected the camera to the camera module port</li>
                                <li>Enabled the camera interface and tested the camera by taking pictures through command prompts following these <a href="https://projects.raspberrypi.org/en/projects/getting-started-with-picamera">instructions</a></li>
                                <li>Attempted taking multiple images and videos with Python code</li>
                                <li>Connected a webcam and took picture with it using this <a href="https://www.raspberrypi.org/documentation/usage/webcams/">guide. However, the pictures from the webcam were blurry and not as clear as those of pi camera</a></li>
                            </ul>
                        </p>
                        
                        <h4>Assembling and Controlling the LEDs</h4>
                        Given my experience from the <a href="sensors.html">introduction to circuitry and sensors</a> classes, and how I have learned about the importance of reading documentations and getting familiar with components pins the <i>hard way</i>, I began this activity with:
                        <ul>
                            <li>Reading the official Raspberry pi GPIO (general-purpose input/output) pins <a href="https://www.raspberrypi.org/documentation/usage/gpio/">documentation. Although, it wasn't detailed enough for me</a></li>
                            <li>Read a more general and detailed explanation of the pins and Pi models<a href="https://siminnovations.com/wiki/index.php?title=General_Raspberry_Pi_I/O_pin_explanation">here</a></li>
                            <li>Installed Mu Code code editor on raspberry Pi</li>
                            <li>Assembled an LED and a resistor on the breadboard, connected the LED legs to Pi's (Ground and 3.3V) pins and blinked the LED using this <a href="https://projects.raspberrypi.org/en/projects/physical-computing/2">guide</a></li>
                            <li>Read the <a href="Gpiozero.readthedocs.io/en/stable/recipes.html">GPIO documentation to get familiar with the GPIO LED built-in funtions</a></li>
                            <li>Made a simple traffic light controller with a green, a red and a yellow LED and blinked them sequentially</li>
                            <li>Progressed to assemble 12 LEDs on the breadboard and connect them to pi GPIO pins </li>
                            <li>Wrote the code for the timer-based traffic controller</li>                         
                        </ul>
                        <div class="row">
                            <figure class="col-lg-4" >
                                <img class="img img-fluid" src="assets/img/demo-1-led.jpg" alt="" />
                                <figcaption><em>An LED connected to the Raspberry Pi</em></figcaption>
                            </figure>
                            <figure class="col-lg-4" >
                                <img class="img img-fluid" src="assets/img/demo-3-led.jpg" alt="" />
                                <figcaption><em>Iteratively lit up each of 3 LEDs in turns</em></figcaption>
                            </figure>
                            <figure class="col-lg-4" >
                                <img class="img img-fluid" src="assets/img/demo-12-led.jpg" alt="" />
                                <figcaption><em>Connected and lit up 12 LEDs</em></figcaption>
                            </figure>
                        </div>
                        The image below is the circuit's design. It illustrates the LEDs', resistors', and the GPIO pins connections in the traffic light system circuitry.
                        <figure class="col-lg-8" >
                            <img class="img img-fluid" src="assets/img/demo-traffic-model.jpg" alt="" />
                            <figcaption><em>The circuit design of the system</em></figcaption>
                        </figure>
                        <h5>Challenges and (Re)solutions</h5>
                        <ul>
                            <li>Although, I had read and comprehended the GPIO pins configuration, and I knew the LEDs power requirement is 3.3V-5V. However, connecting the LEDs to the 5V pin zapped them. It took burning out 3 LEDs to realize this, and made me decide to sick to 3.3V.</li>
                            <li>When I connected the 3 LEDs to pi, the LEDs wouldn't light up, this I discovered was due to the fact that I mixed up my connections to power and ground while connecting the LEDs (connected the wire for ground to power and vice versa). Undoing that made the circuit work as expected.</li>
                            <li>Also, I noticed one of the LED's light was faint, after playing around with positions of the LEDs, I discovered this happened to LEDs connected to a particular resistor, changing the resistor brightened up the LEDs. This was a 1k resistor while others were 220R</li>
                            <li>Progressed to assemble 12 LEDs (4 red, 4 green, 4 yellow) for the 4-way crossroad light control</li>
                        </ul>

                        <h4>Traffic Controller Algorithm</h4>
                        After building the timer-based traffic controller, I needed to make the system intelligent and sensitive to changes in traffic scenarios - this is where computer vision comes in. The way the system is intended to work is it iteratively: 
                        <ul>
                            <li>CaptureÂ real-time images of the road</li>
                            <li>Detect the number of cars on each traffic</li>
                            <li>DetermineÂ theÂ roadÂ withÂ theÂ maximumÂ cars</li>
                            <li>Stops other traffics and passÂ theÂ trafficÂ withÂ theÂ maxÂ number of cars</li>
                            <li>IfÂ the roads have equal number of road,Â then pass the next road on the sequence</li>
                            <li>If there is an error capturingÂ image or using the machine learning model, then activate timer-based controller</li>
                        </ul>
                        <h4>Computer Vision with Raspberry Pi</h4>
                        To enable the system to be able to "see" what's happening in real-time, I needed it to deploy computer vision algorithms. Even though I had no computer-vision experience prior to this, I was able to achieve this; but not without its frustrating challenges.
                        <h5>Challenges and (Re)solutions</h5>
                        <ul>
                            <li><b>Training a model from scratch</b> - to build a machine learning model from scratch, I needed to:
                                <ul>
                                    <li>Gather images of cars and traffic, prepare them (crop, label and annotate them), split them into train and test sets. Training really good models will require thousands of images, preparing thousands of images sounded like a lot for me to do in a short period.</li> 
                                    <li>Build the model and export it for deployment. To build the model, I needed to choose between Keras, Pytorch, Tensorflow, Fast.ai, etc., all of which I was not familiar with. Where do I start learning these and how do I decide which I best for me?</li>
                                </ul>                               
                                These made me decide to explore pre-trained models and optimize them for my project.
                                <li><b>Working with Yolo3 Model</b> - after reading tons of articles, watching overwhelming tutorial videos and exploring Github repositories, I was able to set up my Raspberry pi for image processing by following this <u><a href="https://www.youtube.com/watch?v=H7k1YApU0pg">guide</a></u>, then I tested it and learned the principles of object detection <u><a href="https://www.youtube.com/watch?v=VF8M9DdZ_Aw">here</a></u>. Afterwards, I came across <a href="https://towardsdatascience.com/count-number-of-cars-in-less-than-10-lines-of-code-using-python-40208b173554">this article</a> where I can detect and count the cars in an image in <b>10 lines of Python code!</b></li> 
                                This and other Yolo guides I found worked perfectly in Google Colab as seen in the below images.
                                <br/>
                                <div class="row">
                                    <figure class="col-lg-6" >
                                        <img class="img img-fluid" src="assets/img/demo-yolo-1.png" alt="" />
                                        <figcaption><em>First YOLO attempt using the "10 lines of Code"</em></figcaption>
                                    </figure>
                                    <figure class="col-lg-6" >
                                        <img class="img img-fluid" src="assets/img/demo-yolo-2.png" alt="" />
                                        <figcaption><em>Another YOLO attempt using a guide from <u><a href="https://github.com/mozanunal/yoloOnGoogleColab">here</a></u></em></figcaption>
                                    </figure>
                                </div>
                                However, whenever I run it in Raspberry pi it:
                                <ul>
                                    <li>Takes hours to run the model</li>
                                    <li>Freezes Raspberry Pi - which I found out is due the processing power and memory consumed in training the model. I had to restart Pi some times</li>
                                    <li>Returns no output - not even an error message after freezing pi for hours.</li>
                                </ul>
                                Discussing this individually with Sam, Zena, Johan, Rodolfo, and Victor brought up suggestions like:
                                <ul>
                                    <li>Transferring the captured images to Google Colab for machine learning processing, and sending the number of cars to Raspberry pi. However, I couldn't figure out how to make Google Colab detect that new images have been uploaded. Also, this will require the system to work online in contrast to my plan of having an offline solution</li>
                                    <li>Reducing the images sizes and make the image black and white - Tried it, didn't work. The issues were with the model itself, not the images.</li>
                                    <li>Setting up a machine learning server -  this will require constant connection to the internet.</li>
                                    <li>Restarting the project afresh - I uninstalled Raspbian and wiped the SD card and started afresh.</li>
                                    <li>Using lite versions of the models - I never knew Tensorflow model had lite versions! Since I was starting afresh, I decided to try out TensorFlow Lite</li>
                                </ul>
                            </li>
                        </ul>
                        <h4>Working with Tensorflow Lite Models</h4>
                        <p>
                            In this phase, I created a virtual environment in Pi (to avoid having to restart) and installed TF Lite there - at this point, Johan had also given me Google Coral Edge TPU USB Accelerator to help accelerate my machine learning processes. I was able to set up TF Lite and the USB Accelerator following this <u><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi">guide</a></u>, and I was able to classify images with it in seconds. However, I wanted to detect objects in images and not classify the images and following <a href="https://github.com/google-coral/tflite/tree/master/python/examples/detection">this guide</a> from Coral's Github page only resulted in errors.
                        </p>
                        <p>
                            Hours/Days of surfing the internet led me to this <a href="https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md">detailed guide</a> from Edge Electronics on how to run TensorFlow Lite object detection models on the Raspberry Pi using their sample code. I decided to work with the MobileNet SSD model from <a href="https://coral.ai/models/">coral models list</a> as it was optimized to perform object detection on microprocessors like Raspberry pi, and it can detect up to 90 objects. Running the model on a traffic image resulted in the below image.
                            <div class="row">
                                <figure class="col-lg-6" >
                                    <img class="img img-fluid" src="assets/img/demo-tflite.jpg" alt="" />
                                    <figcaption><em>TFlite attempt at object detection</em></figcaption>
                                </figure>
                            </div>
                        </p>
                        <h5>Challenges and (Re)solutions</h5>
                        <ul>
                            <li>Even though TF Lite works on Raspberry pi, it has less accuracy than YOLO and can only detect 10 objects in an image.</li>
                            <li>Given how inaccurate the TF lite models are, I attempted training my Lite model from scratch. Following this guide shows that I would require Nvidia GPU, installing Anaconda, CUDA Tool kit and CuDNN on my system. There was no way I could get Nvidia in such short time. So, I tried retraining Coral's model using this <a href="https://coral.ai/docs/edgetpu/retrain-detection/#compile-the-model-for-the-edge-tpu">guide</a>. However, this guide seem to have been prepared for experts and I had difficulty understanding the content.</li>
                            <li>In order to bypass this "10 objects" constraint in the MobileNet SSD model, I needed to modify the model to detect more than 10 objects. I reached out to Kathy Reid who really took her time to guide me and directed me towards the file I needed to modify to be able to modify the model</li>
                        </ul>
                        Modifying the model by reducing its accuracy threshold resulted in increasing the number of detected objects (I was surprised!) as seen in the below image.
                        <div class="row">
                            <figure class="col-lg-6" >
                                <img class="img img-fluid" src="assets/img/demo-tflite-final.png" alt="" />
                                <figcaption><em>TFlite attempt at object detection after modifying its threshold.</em></figcaption>
                            </figure>
                        </div>
                        Afterwards, I increased the number of cars detected by restricting the model to only detect cars in images and I accelerated the model's processing time by modifying it to print dictionaries containing the number of cars on each traffic as output instead of returning annotated images as shown below.
                        <div class="row">
                            <figure class="col-lg-6" >
                                <img class="img img-fluid" src="assets/img/demo-model-output.jpg" alt="" />
                                <figcaption><em>Object detection model output.</em></figcaption>
                            </figure>
                        </div> 
                        Below is a video that captured my excitement when the model finally worked as expected after so many attempts and modification! Haha.  
                        <br/>   
                        <iframe src="https://player.vimeo.com/video/430588953" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe> 

                        <h3>Takeaway Lessons</h3>
                        <ul>
                            <li>3.3V power is not the same as 5V power!</li>
                            <li>Let the amount of current you want to pass through your circuit determine the resistor you use</li>
                            <li>Sometimes, when building scalable and complex systems, some trade-offs have to be made. Like choosing between training the model offline vs online (would have been easier), choosing between YOLO (high accuracy and processing power) and TensorFlow Lite (low accuracy and processing power)</li>
                            <li>When faced with deciding which of really overwhelming list of resources to use, go with the one that is more understandable - have been designed for people at your level of expertise.</li>
                            <li>Avoid the temptation of avoid the seemingly difficult approach or giving up on it while trying or trying out every solution to solving a problem. Pick one, see it through to the end before trying another approach.</li>
                            <li>Project management: even though I had a timeline for the project at the beginning, being stuck on making getting a working machine learning model for the system took most of time and became my only focus; I was not working with the timeline anymore. A talk with Zac about my challenges made me realize that I had ignored other important parts of the system I needed to work on. This helped to redirect my focus and got me back on track.</li>
                        </ul>

                        <h3>Achievement</h3>
                        At the end of the activities, I:
                        <ul>
                            <li>Built an intelligent traffic control system that processes images with computer vision technologies offline.</li>
                            <li>Learned how to create circuit design models and created one for the system's circuit</li>
                            <li>Understood the basic principles of machine learning, image processing and object detection and know the difference between image classification and object detection</li>
                            <li>Learned how to set up Raspberry pi, TensorFlow runtime, Coral USB accelerator create python virtual environment.</li>
                            <li>Deployed object detection models in Raspberry pi and also modified their outputs</li>
                            <li>Know how to program and control LEDs with Raspberry pi</li>
                            <li>Am more familiar with deep learning frameworks like Tensorflow and computer vision models.</li>
                            <li>Learned how to download datasets from Kaggle to Google Drive and make it accessible in Google Colab for processing while trying to train my models from scratch</li>
                            <li>Learned about traffic control systems in deployment, how they are controlled and maintained.</li>
                        </ul>
                        
                        <h3>Limitations and Future works</h3>
                        <ul>
                            <li>The current system does not has no memory of its previous passes - if one traffic continues having the most cars, it continues passing the traffic until it becomes less than some other traffic. I will like to update it to limit its number of consecutive passes for a traffic</li>
                            <li>In this system, the images is not processed instantaneously. It does this while the traffic is waiting for the next pass</li>
                            <li>The current model's accuracy is really low. I intend to learn more about deep learning and how to train models so I can build a suitable model for the system.</li>
                        </ul>

                        <p>
                            Overall, working on the maker project gave me an experience that involved exploiting all the skills I have learned so far which includes - coding in Python, circuitry and sensors, data collection and analysis, networking, machine learning; and framing questions about future cyber-physical systems, their scalability, reliability and ethics. Documenting my challenges and achievements, helped me in reflecting on my progress and in communicating it to others.
                        </p>
                        <h3>Learning Resources</h3>
                        Below is a list of the links I learned from as I worked toward creating the traffic light:
                        <ul>
                            <li>Traffic image source: https://thewest.com.au/news/traffic/perth-hit-by-traffic-chaos-as-fatal-crashes-close-kwinana-freeway-and-leach-highway-ng-b881341576z</li>
                            <li>Getting started with Raspberry pi: https://projects.raspberrypi.org/en/projects/raspberry-pi-getting-started/</li>
                            <li>Getting started with pi-camera: https://projects.raspberrypi.org/en/projects/getting-started-with-picamera/</li>
                            <li>Setting up webcame in raspberry pi: https://www.raspberrypi.org/documentation/usage/webcams/</li>
                            <li>Raspberry pi GPIO pin explained: https://www.raspberrypi.org/documentation/usage/gpio/</li>
                            <li>A simpler expla of the GPIO pins: https://siminnovations.com/wiki/index.php?title=General_Raspberry_Pi_I/O_pin_explanation</li>
                            <li>Installing Python Packages in Raspberry pi: https://www.raspberrypi.org/documentation/linux/software/python.md</li>
                            <li>Assembling the LEDs: https://projects.raspberrypi.org/en/projects/physical-computing/</li>
                            <li>GPIO zero module documentation: Gpiozero.readthedocs.io/en/stable/recipes.html</li>
                            <li>Preparing raspberry pi for image processing: 
                                https://www.bitsnblobs.com/getting-started-with-opencv-image-processing/ https://www.youtube.com/watch?v=H7k1YApU0pg</li>
                            <li>Using raspberry pi for motion detection: https://www.bitsnblobs.com/basic-object-motion-detection-using-a-rpi/ https://www.youtube.com/watch?v=VF8M9DdZ_Aw</li>
                            <li>Counting cars in images with YOLO in 10 lines of code: https://towardsdatascience.com/count-number-of-cars-in-less-than-10-lines-of-code-using-python-40208b173554</li>
                            <li>Image classification with TensorFlow lite: https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi</li>
                            <li>Object detection with TF Lite on Raspberry pi: https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md</li>
                            <li>Saving Kaggle dataset in Google Drive and using them in colab: https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a</li>
                            <li>Kaggle dataset used: https://www.kaggle.com/jessicali9530/stanford-cars-dataset</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>
        <!-- Contact-->
        <section class="contact-section bg-black" id="contact">
            <div class="container">
                <div class="row">
                    <div class="col-md-4 mb-3 mb-md-0">
                        <div class="card py-4 h-100">
                            <div class="card-body text-center">
                                <i class="fas fa-globe text-primary mb-2"></i>
                                <h4 class="text-uppercase m-0">Website</h4>
                                <hr class="my-4" />
                                <div class="small text-black-50">https://memmusty.github.io/3AInstitute/</div>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-4 mb-3 mb-md-0">
                        <div class="card py-4 h-100">
                            <div class="card-body text-center">
                                <i class="fas fa-envelope text-primary mb-2"></i>
                                <h4 class="text-uppercase m-0">Email</h4>
                                <hr class="my-4" />
                                <div class="small text-black-50"><a href="#!">memunati@gmail.com</a></div>
                            </div>
                        </div>
                    </div>
                    <div class="col-md-4 mb-3 mb-md-0">
                        <div class="card py-4 h-100">
                            <div class="card-body text-center">
                                <i class="fas fa-mobile-alt text-primary mb-2"></i>
                                <h4 class="text-uppercase m-0">Phone</h4>
                                <hr class="my-4" />
                                <div class="small text-black-50">+234-817-587-3064</div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="social d-flex justify-content-center">
                    <a class="mx-2" href="https://www.linkedin.com/in/memunat-ajoke-ibrahim/"><i class="fab fa-linkedin"></i></a>
                    <a class="mx-2" href="https://github.com/memmusty/"><i class="fab fa-github"></i></a>
                    <a class="mx-2" href="https://twitter.com/_memunat_"><i class="fab fa-twitter"></i></a>
                    <a class="mx-2" href="https://www.facebook.com/memunatj"><i class="fab fa-facebook-f"></i></a>
                </div>
            </div>
        </section>
        <!-- Footer-->
        <footer class="footer bg-black small text-center text-white-50"><div class="container">Copyright Â© MemunatI. 2020</div></footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
